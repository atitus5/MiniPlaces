{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example -- softmax regression\n",
    "\n",
    "MNIST is a simple computer vision dataset. \n",
    "- It consists of images of handwritten digits from 0-9, and their image labels;\n",
    "- Each image is 28 pixels by 28 pixels;\n",
    "- We can flatten this array into a vector of 28x28 = 784 numbers, so MNIST images is a tensor (an n-dimensional array) with a shape of [55000, 784];\n",
    "- MNIST labels is a [55000, 10] array of floats.\n",
    "\n",
    "![](images/mnist-train-xs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "data_dir = 'MNIST_data/'\n",
    "mnist = read_data_sets(data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# check our data shape\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bab8470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one image and label\n",
    "plt.imshow(mnist.train.images[8].reshape(28,28)).set_cmap('Greys')\n",
    "print(mnist.train.labels[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct placeholders as the input ports to the graph\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "#print x.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define network trainable parameters\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "#print W.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define graph operations\n",
    "y_ = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss (cross entropy loss -\\sum y * log(y_))\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer for training\n",
    "train_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the operation that initializes variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: 0\n",
      "Training iterations: 100\n",
      "Training iterations: 200\n",
      "Training iterations: 300\n",
      "Training iterations: 400\n",
      "Training iterations: 500\n",
      "Training iterations: 600\n",
      "Training iterations: 700\n",
      "Training iterations: 800\n",
      "Training iterations: 900\n",
      "Testing Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    # initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Train for 1000 iterations\n",
    "    batch_size = 100\n",
    "    training_iters = 1000\n",
    "    for i in range(training_iters):\n",
    "        # load a batch of data\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # feed data into placeholder, run optimizer \n",
    "        _ = sess.run([train_optimizer], feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('Training iterations:', i)\n",
    "    \n",
    "    # Evaluate the trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # Calculate accuracy for 500 mnist test images\n",
    "    accuracy_val = sess.run(accuracy, feed_dict={x: mnist.test.images[:500], y: mnist.test.labels[:500]})\n",
    "    print('Testing Accuracy:', accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
